{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the meat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "With increasingly dire climate change forecasts, concerned individuals are asking how they can minimize their carbon footprint. Recent research suggests that reducing one's consumption of meat, in particular beef, is one of the highest impact actions an individual can take. To examine this topic, we will explore the popularity and prevalence of meat in recipes. Specifically, we plan to extract the ingredients from a recipe database and calculate the carbon footprint of recipes\n",
    "\n",
    "Finally, we hope to directly relate this data to the issue of climate change by estimating a rating reflecting the carbon footprint of meat in recipes and the environmental impact of consumers' diets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import os, os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER='data'\n",
    "SAMPLE_DATA_FOLDER = DATA_FOLDER + '/sample_400/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction and cleaning\n",
    "\n",
    "Our recipe dataset contains recipes from the [From Cookies to Cooks](http://infolab.stanford.edu/~west1/from-cookies-to-cooks/), combining recipes from 14 high-traffic websites. We start by extracting all the information we want from the HTML files, that is: title, ingredients and meat or animal protein ingredients, tags, ratings in order to explore the recipes in more detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipe webpage scraping\n",
    "The websites' HTML sources are rich in information. However, the information we wantfrom these pages is rather limited. We extract the information we need from the websites, clean and pre-process the data and save it as a CSV file for easy retrieval in further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_page(soup, page):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        soup\n",
    "        page: 'allrecipes', 'epicurious', 'food_network', 'food_com', 'betty_crocker', 'my_recipes' , others not implemented yet\n",
    "    \n",
    "    Output:\n",
    "        tags = list of tags assigned to the recipe\n",
    "        ings = list of ingredients\n",
    "        ing_amounts = amounts of ingredients\n",
    "    \"\"\"\n",
    "    ings = []\n",
    "    ing_amnts = []\n",
    "    tags = []\n",
    "        \n",
    "    if page == 'allrecipes':\n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeCategory\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag['content'])           \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('li', class_=\"plaincharacterwrap ingredient\")\n",
    "        if ing_wrap:\n",
    "            for ing in ing_wrap:\n",
    "                ings.append(ing.getText())\n",
    "        else:\n",
    "            ing_wrap=soup.find_all(itemprop=\"recipeIngredient\")\n",
    "            for ing in ing_wrap:\n",
    "                ings.append(ing.getText())\n",
    "            #if not ing_wrap:\n",
    "                #print('alternative format needed for Allrecipes')\n",
    "            #for ing in ing_wrap:\n",
    "            #    ing_amnts.append(ing.find(itemprop='amount').text)\n",
    "            #    ings.append(ing.find(itemprop='name').text)\n",
    "        \n",
    "        \n",
    "    elif page == 'epicurious':       \n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeCuisine\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())    \n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeCategory\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())        \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find('div', id=\"ingredients\")\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.string)\n",
    "      \n",
    "    \n",
    "    elif page == 'food_network':  \n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(class_=\"btn grey-tags\")        \n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())      \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('li',class_='ingredient')\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.text)\n",
    "\n",
    "    elif page == 'food_com':      \n",
    "        # Extract tags\n",
    "            #not found          \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('li', class_=\"ingredient\")\n",
    "        if ing_wrap:\n",
    "            for ing in ing_wrap:\n",
    "                ing_amnts.append((ing.find('span',class_='value').text+ ' '+ing.find('span',class_='type').text))\n",
    "                #ings.append(ing.find('span', class_='name').text)\n",
    "                #ings.append((ing.find('span',class_='value').text+ ' '+ing.find('span',class_='type').text + ' ' + ing.find('span', class_='name').text)\n",
    "        else:\n",
    "            ing_wrap=soup.find_all(class_=\"name\")\n",
    "            for ing in ing_wrap:\n",
    "                ings.append(ing.getText())\n",
    "    \n",
    "    elif page == 'betty_crocker':   \n",
    "        # Extract tags\n",
    "            #not found    \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('dl', class_='ingredient')\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.getText())\n",
    "    \n",
    "\n",
    "    elif page == 'my_recipes':\n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeType\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())  \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all(itemprop=\"ingredient\")\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.text)\n",
    "        \n",
    "    #other websites    \n",
    "        # Extract tags   \n",
    "        # Extract ingredients \n",
    "        \n",
    "#    if not ing_wrap:  #return warning if website is recognized but format/data extraction is not successful\n",
    "#        print('*******')\n",
    "#         print('NEED NEW FORMAT')  \n",
    "#       print('*******')\n",
    "    \n",
    "    #if not tags:\n",
    "        #print('no tags found :( ')\n",
    "        \n",
    "    return tags, ings, ing_amnts\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_website(soup):\n",
    "    \"\"\"\n",
    "    Finds if the page is a recipe and which website it comes from\n",
    "    \"\"\"\n",
    "    is_recipe = True\n",
    "    \n",
    "    if 'Allrecipes' in soup.title.string:\n",
    "        website = 'allrecipes'               \n",
    "              \n",
    "    elif 'Epicurious' in soup.title.string:\n",
    "        website = 'epicurious'\n",
    "    \n",
    "    elif 'Food Network' in soup.title.string:\n",
    "        website = 'food_network'\n",
    "        \n",
    "    elif 'Food.com' in soup.title.string:\n",
    "        website == 'food_com'\n",
    "    \n",
    "    elif 'Betty Crocker' in soup.title.string:\n",
    "        website = 'betty_crocker'\n",
    "               \n",
    "    elif 'MyRecipes' in soup.title.string:\n",
    "        website = 'my_recipes'\n",
    "\n",
    "    else:\n",
    "        website = 'not found'\n",
    "        is_recipe = False\n",
    "        \n",
    "    return is_recipe, website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantity extraction and conversion\n",
    "The amounts of each ingredients are expressed in many different units (imperial or metric) depending on the websites, and even on the recipes. Once we have extracted the ingredients and amounts, we need to convert all different quantities to one single weight unit (fixed to kilograms) in order to process the carbon footprint of selected ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quantity(quant_str):\n",
    "    \"\"\"\n",
    "    Cleans input string and extracts numerical values\n",
    "    Outputs cleaned string, array of numerical values and sum of numerical values\n",
    "    \"\"\"\n",
    "    quant_str=quant_str.replace(\"Â½\",\".5\")\n",
    "    quant_str=quant_str.replace(\"1/2\",\".5\")\n",
    "    quant_str=quant_str.replace(\"1/3\", '.33')\n",
    "    quant_str=quant_str.replace('1/4','.25')\n",
    "    quant_str=quant_str.replace('3/4','.75')\n",
    "    quant_vals=re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", quant_str)\n",
    "    total_quant=np.sum([float(i) for i in quant_vals])\n",
    "    \n",
    "    return quant_str, quant_vals, total_quant\n",
    "\n",
    "\n",
    "def convert_to_kg(quant, unit):\n",
    "    \"\"\"\n",
    "    Converts any input unit (kg, lb, grams, ounces) to kilograms\n",
    "    \"\"\"\n",
    "    \n",
    "    if (unit=='kilogram') or (unit=='kg'):\n",
    "        amnt_kg=quant\n",
    "        #print(quant,'kg')\n",
    "    elif (unit=='pound') or (unit=='lb') or (unit=='lbs') or (unit=='pounds'):\n",
    "        amnt_kg=quant/2.205\n",
    "        #print(amnt_kg,'kg')\n",
    "    elif(unit=='g') or (unit=='gram') or (unit =='grams'):\n",
    "        amnt_kg=quant/1000\n",
    "        #print(amnt_kg,'kg')     \n",
    "    elif(unit=='oz') or (unit=='ounce'):\n",
    "        amnt_kg=quant/35.274\n",
    "        #print(amnt_kg, 'kg')\n",
    "        \n",
    "    return(amnt_kg)\n",
    "\n",
    "def contains_meat_ingredients(ings_in, meat_products_in):\n",
    "    contains_meat=False\n",
    "    meat_ingredients=[]\n",
    "    #meat_ingredients=[False]*len(meat_products_in)\n",
    "    j=0\n",
    "    for i in ings_in:\n",
    "        for meat_product in meat_products_in:\n",
    "            if i != None:\n",
    "                if meat_product in i.casefold(): \n",
    "                    contains_meat=True\n",
    "                    meat_ingredients.append(meat_product)        \n",
    "                    #meat_ingredients[j]=True\n",
    "        j = j+1\n",
    "                    \n",
    "    return contains_meat, meat_ingredients\n",
    "\n",
    "def extract_meat(ings_in, meat_products_in):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    ings_in= list of ingredients (and quantities)\n",
    "    meat_products_in = list of products that we are searching for\n",
    "    \n",
    "    Outputs:\n",
    "    meat_ingredients_full = list of meat ingredients (full string)\n",
    "    meat_ingredients_base = list of meat ingredients (from base string meat_products)\n",
    "    ing_amnt_out = list of corresponding quanities of meat ingredients in kg (=0 if unit not recognized)\n",
    "    contains_meat = boolean (True if 1+ ingredients are recognized from meat_products list)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    meat_ingredients_full = []\n",
    "    meat_ingredients_base = []\n",
    "    ing_amnt_out=[]\n",
    "    contains_meat=False\n",
    "    \n",
    "    #Find meat products present in the ingredients (ignoring capitals with casefold)\n",
    "    for i in ings_in:\n",
    "        for meat_product in meat_products_in:\n",
    "            if i != None:\n",
    "                if meat_product in i.casefold(): \n",
    "                    contains_meat=True\n",
    "                    meat_ingredients_full.append(i.casefold()) \n",
    "                    meat_ingredients_base.append(meat_product)\n",
    "\n",
    "    #extract amount from string and convert to kg\n",
    "    for meat_i in meat_ingredients_full:\n",
    "        meat_i_quant_kg=0\n",
    "        meat_i, quantity_vals, total_quantity=check_quantity(meat_i) #pass string, return cleaned string and total quantity\n",
    "\n",
    "        for u in units: \n",
    "            if u in meat_i:\n",
    "                meat_i_quant_kg = convert_to_kg(total_quantity,u)\n",
    "        ing_amnt_out.append(meat_i_quant_kg)\n",
    "        #if meat_i_quant_kg==0:\n",
    "        #    print('Units not recognized for: '+meat_i)\n",
    "                    \n",
    "    \n",
    "    return meat_ingredients_full, meat_ingredients_base, ing_amnt_out, contains_meat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'amnt_kg' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-39c89dfd8f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mextract_amount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mingredient_amounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeat_products\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-229-39c89dfd8f22>\u001b[0m in \u001b[0;36mextract_amount\u001b[0;34m(ings_in, ing_amnt_in, meat_products_in)\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeat_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m#        print('Quantity in '+ u + ' converted to ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                     \u001b[0mmeat_i_quant_kg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_kg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_quantity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0ming_amnt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeat_i_quant_kg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;31m#if meat_i_quant_kg==0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-b3787ceb4d49>\u001b[0m in \u001b[0;36mconvert_to_kg\u001b[0;34m(quant, unit)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#print(amnt_kg, 'kg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamnt_kg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcontains_meat_ingredients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mings_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeat_products_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'amnt_kg' referenced before assignment"
     ]
    }
   ],
   "source": [
    "def extract_amount(ings_in, ing_amnt_in,meat_products_in):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    ings_in= list of ingredients (and quantities)\n",
    "    ing_amnt_in =  list of quantities corresponding to ingredients (empty if quanitites are included in ings_in)\n",
    "    meat_products_in = list of products that we are searching for\n",
    "    \n",
    "    Outputs:\n",
    "    meat_ingredients_full = list of meat ingredients (full string)\n",
    "    meat_ingredients_base = list of meat ingredients (from base string meat_products)\n",
    "    ing_amnt_out = list of corresponding quanities of meat ingredients in kg (=0 if unit not recognized)\n",
    "    contains_meat = boolean (True if 1+ ingredients are recognized from meat_products list)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    meat_ingredients_full = []\n",
    "    meat_ingredients_base = []\n",
    "    ing_amnt_out=[]\n",
    "    contains_meat=False\n",
    "    \n",
    "    #Find meat ingredients\n",
    "    for i in ings_in:\n",
    "        for meat_product in meat_products_in:\n",
    "            if i != None:\n",
    "                #are any of the meat products present in the ingredients? (ignoring capitals with casefold)\n",
    "                if meat_product in i.casefold(): \n",
    "                    contains_meat=True\n",
    "                    meat_ingredients_full.append(i.casefold()) \n",
    "                    meat_ingredients_base.append(meat_product)\n",
    "\n",
    "    #extract amount from string if amount is not directly available in ing_amnt_in\n",
    "    if not ing_amnt_in: #if amount is empty \n",
    "        for meat_i in meat_ingredients_full:\n",
    "            meat_i_quant_kg=0\n",
    "            \n",
    "            #print('------------')\n",
    "            #print('Ingredient: ', meat_i) \n",
    "            meat_i, quantity_vals, total_quantity=check_quantity(meat_i) #pass string, return cleaned string and total quantity\n",
    "\n",
    "            \n",
    "            #find units and convert to kg\n",
    "            for u in units: \n",
    "                if u in meat_i:\n",
    "            #        print('Quantity in '+ u + ' converted to ')\n",
    "                    meat_i_quant_kg = convert_to_kg(total_quantity,u)\n",
    "            ing_amnt_out.append(meat_i_quant_kg)\n",
    "            #if meat_i_quant_kg==0:\n",
    "            #    print('Units not recognized for: '+meat_i)\n",
    "                \n",
    "                \n",
    "    else:# if amount is directly available through ing_amnt\n",
    "        #print('Amount available')\n",
    "        for meat_i in meat_ingredients_full:\n",
    "            meat_i_quant_kg=0\n",
    "            #print('------------')\n",
    "            #print('Ingredient: ', meat_i)\n",
    "            \n",
    "            #get index of ingredient in meat_ingredients_full\n",
    "            meat_amount=ing_amnt_in[ings_in.index(meat_i)]\n",
    "            meat_amount, quantity_vals, total_quantity=check_quantity(meat_amount)\n",
    "            \n",
    "            #find units and convert to kg\n",
    "            for u in units: \n",
    "                if u in meat_amount.casefold():\n",
    "                    meat_i_quant_kg = convert_to_kg(total_quantity,u)\n",
    "                    #print('Quantity in '+ u + ' converted to ', meat_i_quant_kg, 'kg')\n",
    "            ing_amnt_out.append(meat_i_quant_kg)\n",
    "            #if meat_i_quant_kg==0:\n",
    "                #print('Units not recognized for: '+meat_amount+meat_i)\n",
    "    return meat_ingredients_full, meat_ingredients_base, ing_amnt_out, contains_meat\n",
    "\n",
    "\n",
    "    \n",
    "extract_amount(ingredients,ingredient_amounts, meat_products)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define carbon footprint of meat ingredients\n",
    "Animal agriculture is one of the leading sources of the carbon-impact of a recipe. We start by assigning a carbon footprint to each meat ingredient and could later on extend it to other animal products. \n",
    "The functions below assign a carbon footprint to each meat ingredient of the recipes.\n",
    "\n",
    "Source of data: [GreenEatz](https://www.greeneatz.com/foods-carbon-footprint.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>CO2 Kilos Equivalent</th>\n",
       "      <th>Car MilesÂ Equivalent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamb</td>\n",
       "      <td>39.2</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beef</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pork</td>\n",
       "      <td>12.1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>10.9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuna</td>\n",
       "      <td>6.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food  CO2 Kilos Equivalent  Car MilesÂ Equivalent\n",
       "Rank                                                     \n",
       "1        Lamb                  39.2                    91\n",
       "2        Beef                  27.0                    63\n",
       "3      Cheese                  13.5                    31\n",
       "4        Pork                  12.1                    28\n",
       "5      Turkey                  10.9                    25\n",
       "6     Chicken                   6.9                    16\n",
       "7        Tuna                   6.1                    14\n",
       "8        Eggs                   4.8                    11"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data from xls file\n",
    "carbon_footprint = pd.read_excel('data/carbon_footprint_protein.xls', sheet_name='meat_dairy_eggs', index_col=0)\n",
    "carbon_footprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of meat ingredients\n",
    "meat_products = carbon_footprint['Food'].tolist()\n",
    "#same list copied without caps\n",
    "meat_products = ['lamb', 'beef', 'cheese', 'pork', 'turkey', 'chicken', 'tuna', 'egg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = ['pounds','grams','oz','ounces','kg','kilograms','lbs' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate carbon footprint\n",
    "#input ingredients and amounts\n",
    "#output carbon footprint\n",
    "def carbon_fp (meat_ingredients, meat_products, carbon_footprint=carbon_footprint):\n",
    "    \"\"\"\n",
    "    takes a list of ingredients contributing to co2 and returns carbon footprint (per meat ingredient)\n",
    "    \"\"\"\n",
    "    meat_footprints = [0]*len(meat_products)\n",
    "    j=0\n",
    "    \n",
    "    for meat in meat_products:\n",
    "        for i in meat_ingredients:\n",
    "            if i == meat:\n",
    "                meat_footprints[j]=carbon_footprint['Food'=='meat']['CO2 Kilos Equivalent']\n",
    "        j = j+1\n",
    "                \n",
    "    total_carbon = np.cumsum(meat_footprints)\n",
    "    \n",
    "    return total_carbon, meat_footprints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction and cleaning loop\n",
    "Below we extract the data from the recipes of our html dataset and save it in dataframes. Our goal here is to extract the ingredients and assign a carbon-impact rating to the highest impact ingredients (meat or animal protein) in the recipes.\n",
    "\n",
    "To extract protein-rich ingredients from animal source in order to calculate the main carbon footprint of the recipe, we use an extra database listing the main protein sources and carbon impact. Source of data: [GreenEatz](https://www.greeneatz.com/foods-carbon-footprint.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loop for all recipes in folder\n",
    "data=[]\n",
    "step=0\n",
    "\n",
    "verbose = 0 #verbose outputs\n",
    "\n",
    "for filename in os.listdir(SAMPLE_DATA_FOLDER):\n",
    "    with open(SAMPLE_DATA_FOLDER+filename) as f:\n",
    "        isTrue=False\n",
    "        count_exceptions=0\n",
    "        \n",
    "        try:\n",
    "            page = f.read()\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            \n",
    "            #check webpage and extract ingredients if recognised as recipe\n",
    "            is_recipe, website = find_website(soup)\n",
    "            \n",
    "            \n",
    "            if is_recipe:\n",
    "                \n",
    "                #tags, ingredients = analyse_page(soup, website)\n",
    "                tags, ingredients, ingredient_amounts = analyse_page(soup, website)\n",
    "\n",
    "                if ingredients:\n",
    "                    \n",
    "                    \n",
    "                    has_meat, meat_ingredients = contains_meat_ingredients(ingredients, meat_products)\n",
    "   \n",
    "\n",
    "                    if verbose: \n",
    "                        print('Recipe Analysed: '+soup.title.string)\n",
    "                        \n",
    "                        print('contains meat:'+str(has_meat))\n",
    "                        print(meat_ingredients)\n",
    "                        \n",
    "                        print('{0} Ingredients: '.format(len(ingredients)))\n",
    "                        print(ingredients)\n",
    "\n",
    "                        print('{0} tags:'.format(len(tags)))\n",
    "                        print(tags)\n",
    "                            \n",
    "                data.append([soup.title.string, has_meat, meat_ingredients, tags])\n",
    "\n",
    "            #else:\n",
    "                #print('not a recipe')\n",
    "        except:\n",
    "            count_exceptions=count_exceptions+1\n",
    "            #print('Exception')\n",
    "    step=step+1\n",
    "    \n",
    "    if verbose: \n",
    "        print('-------------------------------------')\n",
    "        \n",
    "#    if step>=100:\n",
    "#        break\n",
    "\n",
    "column_labels=['Recipe Title', 'Has meat', 'Meat types', 'Tags']#missing: 'Carbon footprint', 'Rating', 'Tags'\n",
    "recipes_df = pd.DataFrame(data, columns = column_labels)\n",
    "\n",
    "#save the data as csv for in depth analysis\n",
    "recipes_df.to_csv(DATA_FOLDER+'/recipes_data')\n",
    "\n",
    "recipes_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
