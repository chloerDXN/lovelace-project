{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meet the meat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "With increasingly dire climate change forecasts, concerned individuals are asking how they can minimize their carbon footprint. Recent research suggests that reducing one's consumption of meat, in particular beef, is one of the highest impact actions an individual can take. To examine this topic, we will explore the popularity and prevalence of meat in recipes. Specifically, we plan to extract the ingredients from a recipe database and calculate the carbon footprint of recipes\n",
    "\n",
    "Finally, we hope to directly relate this data to the issue of climate change by estimating a rating reflecting the carbon footprint of meat in recipes and the environmental impact of consumers' diets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import os, os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER='data'\n",
    "#SAMPLE_DATA_FOLDER = DATA_FOLDER + '/htmlSample/'\n",
    "SAMPLE_DATA_FOLDER = DATA_FOLDER + '/sample_400/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FILE='data/htmlSample/ff6da2b8d426c56ae77beda595bdcfea.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction and cleaning\n",
    "\n",
    "Our recipe dataset contains recipes from the [From Cookies to Cooks](http://infolab.stanford.edu/~west1/from-cookies-to-cooks/), combining recipes from 14 high-traffic websites. We start by extracting all the information we want from the HTML files, that is: title, ingredients and meat or animal protein ingredients, tags, ratings in order to explore the recipes in more detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recipe webpage scraping\n",
    "The websites' HTML sources are rich in information. However, the information we wantfrom these pages is rather limited. We extract the information we need from the websites, clean and pre-process the data and save it as a CSV file for easy retrieval in further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_page(soup, page):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        soup\n",
    "        page: 'allrecipes', 'epicurious', 'food_network', 'food_com', 'betty_crocker', 'my_recipes' , others not implemented yet\n",
    "    \n",
    "    Output:\n",
    "        tags = list of tags assigned to the recipe\n",
    "        ings = list of ingredients\n",
    "    \"\"\"\n",
    "    ings = []\n",
    "    ing_amnts = []\n",
    "    tags = []\n",
    "        \n",
    "    if page == 'allrecipes':\n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeCategory\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag['content'])           \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('li', class_=\"plaincharacterwrap ingredient\")\n",
    "        if ing_wrap:\n",
    "            for ing in ing_wrap:\n",
    "                ings.append(ing.getText())\n",
    "        else:\n",
    "            ing_wrap=soup.find_all(itemprop=\"recipeIngredient\")\n",
    "            for ing in ing_wrap:\n",
    "                ings.append(ing.getText())\n",
    "            if not ing_wrap:\n",
    "                print('alternative format needed for Allrecipes')\n",
    "            #for ing in ing_wrap:\n",
    "            #    ing_amnts.append(ing.find(itemprop='amount').text)\n",
    "            #    ings.append(ing.find(itemprop='name').text)\n",
    "        \n",
    "        \n",
    "    elif page == 'epicurious':       \n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeCuisine\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())    \n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeCategory\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())        \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find('div', id=\"ingredients\")\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.string)\n",
    "      \n",
    "    \n",
    "    elif page == 'food_network':  \n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(class_=\"btn grey-tags\")        \n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())      \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('li',class_='ingredient')\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.text)\n",
    "\n",
    "    elif page == 'food_com':      \n",
    "        # Extract tags\n",
    "            #not found          \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('li', class_=\"ingredient\")\n",
    "        if ing_wrap:\n",
    "            for ing in ing_wrap:\n",
    "                ing_amnts.append((ing.find('span',class_='value').text+ ' '+ing.find('span',class_='type').text))\n",
    "                ings.append(ing.find('span', class_='name').text)\n",
    "        else:\n",
    "            ing_wrap=soup.find_all(class_=\"name\")\n",
    "            for ing in ing_wrap:\n",
    "                ings.append(ing.getText())\n",
    "    \n",
    "    \n",
    "    elif page == 'betty_crocker':   \n",
    "        # Extract tags\n",
    "            #not found    \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all('dl', class_='ingredient')\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.getText())\n",
    "    \n",
    "    \n",
    "    elif page == 'my_recipes':\n",
    "        # Extract tags\n",
    "        tag_wrappers = soup.find_all(itemprop=\"recipeType\")\n",
    "        for tag in tag_wrappers:\n",
    "            tags.append(tag.getText())  \n",
    "        # Extract ingredients\n",
    "        ing_wrap=soup.find_all(itemprop=\"ingredient\")\n",
    "        for ing in ing_wrap:\n",
    "            ings.append(ing.text)\n",
    "        \n",
    "    #other websites    \n",
    "        # Extract tags   \n",
    "        # Extract ingredients \n",
    "        \n",
    "    if not ing_wrap:  #return warning if website is recognized but format/data extraction is not successful\n",
    "        print('*******')\n",
    "        print('NEED NEW FORMAT')  \n",
    "        print('*******')\n",
    "    \n",
    "    #if not tags:\n",
    "        #print('no tags found :( ')\n",
    "        \n",
    "    return tags, ings\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_website(soup):\n",
    "    \"\"\"\n",
    "    Finds if the page is a recipe and which website it comes from\n",
    "    \"\"\"\n",
    "    is_recipe = True\n",
    "    \n",
    "    if 'Allrecipes' in soup.title.string:\n",
    "        website = 'allrecipes'               \n",
    "              \n",
    "    elif 'Epicurious' in soup.title.string:\n",
    "        website = 'epicurious'\n",
    "    \n",
    "    elif 'Food Network' in soup.title.string:\n",
    "        website = 'food_network'\n",
    "        \n",
    "    elif 'Food.com' in soup.title.string:\n",
    "        website == 'food_com'\n",
    "    \n",
    "    elif 'Betty Crocker' in soup.title.string:\n",
    "        website = 'betty_crocker'\n",
    "               \n",
    "    elif 'MyRecipes' in soup.title.string:\n",
    "        website = 'my_recipes'\n",
    "\n",
    "    else:\n",
    "        website = 'not found'\n",
    "        is_recipe = False\n",
    "        \n",
    "    return is_recipe, website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantity extraction and conversion\n",
    "The amounts of each ingredients are expressed in many different units (imperial or metric) depending on the websites, and even on the recipes. Once we have extracted the ingredients and amounts, we need to convert all different quantities to one single weight unit (fixed to kilograms) in order to process the carbon footprint of selected ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_quantity(quant_str):\n",
    "    \"\"\"\n",
    "    Cleans input string and extracts numerical values\n",
    "    Outputs cleaned string, array of numerical values and sum of numerical values\n",
    "    \"\"\"\n",
    "    quant_str=quant_str.replace(\"Â½\",\".5\")\n",
    "    quant_str=quant_str.replace(\"1/2\",\".5\")\n",
    "    quant_str=quant_str.replace(\"1/3\", '.33')\n",
    "    quant_str=quant_str.replace('1/4','.25')\n",
    "    quant_str=quant_str.replace('3/4','.75')\n",
    "    quant_vals=re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", quant_str)\n",
    "    total_quant=np.sum([float(i) for i in quant_vals])\n",
    "    \n",
    "    return quant_str, quant_vals, total_quant\n",
    "\n",
    "\n",
    "def convert_to_kg(quant, unit):\n",
    "    \"\"\"\n",
    "    Converts any input unit (kg, lb, grams, ounces) to kilograms\n",
    "    \"\"\"\n",
    "    \n",
    "    if (unit=='kilogram') or (unit=='kg'):\n",
    "        amnt_kg=quant\n",
    "        #print(quant,'kg')\n",
    "    elif (unit=='pound') or (unit=='lb') or (unit=='lbs') or (unit=='pounds'):\n",
    "        amnt_kg=quant/2.205\n",
    "        #print(amnt_kg,'kg')\n",
    "    elif(unit=='g') or (unit=='gram') or (unit =='grams'):\n",
    "        amnt_kg=quant/1000\n",
    "        #print(amnt_kg,'kg')     \n",
    "    elif(unit=='oz') or (unit=='ounce'):\n",
    "        amnt_kg=quant/35.274\n",
    "        #print(amnt_kg, 'kg')\n",
    "        \n",
    "    return(amnt_kg)\n",
    "\n",
    "def contains_meat_ingredients(ings_in, meat_products_in):\n",
    "    contains_meat=False\n",
    "    meat_ingredients=[]\n",
    "    #meat_ingredients=[False]*len(meat_products_in)\n",
    "    j=0\n",
    "    for i in ings_in:\n",
    "        for meat_product in meat_products_in:\n",
    "            if i != None:\n",
    "                if meat_product in i.casefold(): \n",
    "                    contains_meat=True\n",
    "                    meat_ingredients.append(meat_product)        \n",
    "                    #meat_ingredients[j]=True\n",
    "        j = j+1\n",
    "                    \n",
    "    return contains_meat, meat_ingredients\n",
    "\n",
    "def extract_meat(ings_in, meat_products_in):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    ings_in= list of ingredients (and quantities)\n",
    "    meat_products_in = list of products that we are searching for\n",
    "    \n",
    "    Outputs:\n",
    "    meat_ingredients_full = list of meat ingredients (full string)\n",
    "    meat_ingredients_base = list of meat ingredients (from base string meat_products)\n",
    "    ing_amnt_out = list of corresponding quanities of meat ingredients in kg (=0 if unit not recognized)\n",
    "    contains_meat = boolean (True if 1+ ingredients are recognized from meat_products list)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    meat_ingredients_full = []\n",
    "    meat_ingredients_base = []\n",
    "    ing_amnt_out=[]\n",
    "    contains_meat=False\n",
    "    \n",
    "    #Find meat products present in the ingredients (ignoring capitals with casefold)\n",
    "    for i in ings_in:\n",
    "        for meat_product in meat_products_in:\n",
    "            if i != None:\n",
    "                if meat_product in i.casefold(): \n",
    "                    contains_meat=True\n",
    "                    meat_ingredients_full.append(i.casefold()) \n",
    "                    meat_ingredients_base.append(meat_product)\n",
    "\n",
    "    #extract amount from string and convert to kg\n",
    "    for meat_i in meat_ingredients_full:\n",
    "        meat_i_quant_kg=0\n",
    "        meat_i, quantity_vals, total_quantity=check_quantity(meat_i) #pass string, return cleaned string and total quantity\n",
    "\n",
    "        for u in units: \n",
    "            if u in meat_i:\n",
    "                meat_i_quant_kg = convert_to_kg(total_quantity,u)\n",
    "        ing_amnt_out.append(meat_i_quant_kg)\n",
    "        #if meat_i_quant_kg==0:\n",
    "        #    print('Units not recognized for: '+meat_i)\n",
    "                    \n",
    "    \n",
    "    return meat_ingredients_full, meat_ingredients_base, ing_amnt_out, contains_meat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning function to remove unnecessary cells in ingredient list\n",
    "def remove_spaces(l):\n",
    "    \"\"\"\n",
    "    cleaning function to remove unnecessary cells in ingredient list\n",
    "    \"\"\"\n",
    "    while '' in l:\n",
    "                l.remove('')\n",
    "    while ' ' in l:\n",
    "                l.remove(' ')\n",
    "    return l \n",
    "\n",
    "#idea: calculate carbon foodprint in this function by summing contributions in meat_ingredients\n",
    "#return a list of all meat ingredients and their amount and a is_true=True if the recipe contains meat\n",
    "def analyse_meat(ingredient_list, s):\n",
    "    \"\"\"\n",
    "    takes as argument the ingredient_list and the spacer\n",
    "    returns a list of all meat ingredients in the recipe, and a boolean contains_meat\n",
    "    \"\"\"\n",
    "    meat_ingredients = []\n",
    "    contains_meat=False\n",
    "    for ingredient in ingredient_list:\n",
    "        for meat_product in meat_products:\n",
    "            if meat_product in ingredient.getText():\n",
    "                contains_meat=True\n",
    "                l=ingredient.getText().split(s)\n",
    "                l=remove_spaces(l)\n",
    "                l.append(meat_product)\n",
    "                meat_ingredients.append(l)\n",
    "    return meat_ingredients, contains_meat\n",
    "\n",
    "\n",
    "def get_ingredients(ingredient_wrappers):\n",
    "    \"\"\"\n",
    "    returns a list of all ingredients in the recipe\n",
    "    \"\"\"\n",
    "    ingredients = []\n",
    "    for ingredient in ingredient_wrappers:\n",
    "        ingredients.append(ingredient.getText())    \n",
    "    return ingredients\n",
    "#not sure whether we can give soup and page as arguments..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define carbon footprint of meat ingredients\n",
    "Animal agriculture is one of the leading sources of the carbon-impact of a recipe. We start by assigning a carbon footprint to each meat ingredient and could later on extend it to other animal products. \n",
    "The functions below assign a carbon footprint to each meat ingredient of the recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Food</th>\n",
       "      <th>CO2 Kilos Equivalent</th>\n",
       "      <th>Car MilesÂ Equivalent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamb</td>\n",
       "      <td>39.2</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beef</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>13.5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pork</td>\n",
       "      <td>12.1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turkey</td>\n",
       "      <td>10.9</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chicken</td>\n",
       "      <td>6.9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuna</td>\n",
       "      <td>6.1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Eggs</td>\n",
       "      <td>4.8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Food  CO2 Kilos Equivalent  Car MilesÂ Equivalent\n",
       "Rank                                                     \n",
       "1        Lamb                  39.2                    91\n",
       "2        Beef                  27.0                    63\n",
       "3      Cheese                  13.5                    31\n",
       "4        Pork                  12.1                    28\n",
       "5      Turkey                  10.9                    25\n",
       "6     Chicken                   6.9                    16\n",
       "7        Tuna                   6.1                    14\n",
       "8        Eggs                   4.8                    11"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data from xls file\n",
    "carbon_footprint = pd.read_excel('data/carbon_footprint_protein.xls', sheet_name='meat_dairy_eggs', index_col=0)\n",
    "carbon_footprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of meat ingredients\n",
    "meat_products = carbon_footprint['Food'].tolist()\n",
    "#same list copied without caps\n",
    "meat_products = ['lamb', 'beef', 'cheese', 'pork', 'turkey', 'chicken', 'tuna', 'egg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove first letter to avoid capitalization issues?\n",
    "#'sausage', 'egg', 'cheese', \n",
    "meat_products = ['sausage', 'egg', 'cheese', 'meat', 'beef','pork', 'chicken', 'fish', 'lamb','ham', 'turkey','steak','sirloin','veal','hamburger']\n",
    "units = ['pounds','grams','oz','ounces','kg','kilograms','lbs' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate carbon footprint\n",
    "#input ingredients\n",
    "#identify ingredient ammount\n",
    "#output carbon footprint\n",
    "def carbon_fp (l):\n",
    "    \"\"\"\n",
    "    takes a list of ingredients contributing to co2 and returns carbon footprint\n",
    "    \"\"\"\n",
    "    c=len(l)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction and cleaning loop\n",
    "Below we extract the data from the recipes of our html dataset and save it in dataframes. Our goal here is to extract the ingredients and assign a carbon-impact rating to the highest impact ingredients (meat or animal protein) in the recipes.\n",
    "\n",
    "To extract protein-rich ingredients from animal source in order to calculate the main carbon footprint of the recipe, we use an extra database listing the main protein sources and carbon impact. Source of data: [GreenEatz](https://www.greeneatz.com/foods-carbon-footprint.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alternative format needed for Allrecipes\n",
      "*******\n",
      "NEED NEW FORMAT\n",
      "*******\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipe Title</th>\n",
       "      <th>Has meat</th>\n",
       "      <th>Meat types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cheese and Onion Pie Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[cheese, egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wonton Wrappers Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twice Baked Cheesy Potatoes Recipe - Allreci...</td>\n",
       "      <td>True</td>\n",
       "      <td>[cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mahi Mahi with Coconut Rice and Mango Salsa ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[chicken]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coconut Icebox Cookies Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seattle Dutch Babies Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Baked Asparagus with Balsamic Butter Sauce R...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stuffed Mushrooms with Spinach Recipe - Allr...</td>\n",
       "      <td>True</td>\n",
       "      <td>[cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Oyster Stew Recipe - Allrecipes.com</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Slow Cooker Carnitas Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[pork, chicken]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inside Out Stuffed Peppers Recipe - Allrecip...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Perfect Pumpkin Pie Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cranberry Sauce I Recipe - Allrecipes.com</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Halloween Cookies Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Liver Pate Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[chicken]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Chicken Corn Chowder Recipe - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[chicken, chicken]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Pineapple Angel Food Cake I Recipe - Allreci...</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Asian Ground Beef and Pepper Saute Recipe - ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[beef, beef]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Nancy's Chicken in Puff Pastry Recipe - Allr...</td>\n",
       "      <td>True</td>\n",
       "      <td>[chicken, cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fruit Dip Recipes - Allrecipes.com</td>\n",
       "      <td>True</td>\n",
       "      <td>[chicken, cheese]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Seven Minute Frosting I Recipe - Allrecipes....</td>\n",
       "      <td>True</td>\n",
       "      <td>[egg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wild Rice Pilaf Recipe - Allrecipes.com</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Southern Fried Corn Recipe - Allrecipes.com</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Recipe Title  Has meat  \\\n",
       "0     \n",
       "\tCheese and Onion Pie Recipe - Allrecipes.com\n",
       "      True   \n",
       "1          \n",
       "\tWonton Wrappers Recipe - Allrecipes.com\n",
       "      True   \n",
       "2   \n",
       "\tTwice Baked Cheesy Potatoes Recipe - Allreci...      True   \n",
       "3   \n",
       "\tMahi Mahi with Coconut Rice and Mango Salsa ...      True   \n",
       "4   \n",
       "\tCoconut Icebox Cookies Recipe - Allrecipes.com\n",
       "      True   \n",
       "5     \n",
       "\tSeattle Dutch Babies Recipe - Allrecipes.com\n",
       "      True   \n",
       "6   \n",
       "\tBaked Asparagus with Balsamic Butter Sauce R...     False   \n",
       "7   \n",
       "\tStuffed Mushrooms with Spinach Recipe - Allr...      True   \n",
       "8              \n",
       "\tOyster Stew Recipe - Allrecipes.com\n",
       "     False   \n",
       "9     \n",
       "\tSlow Cooker Carnitas Recipe - Allrecipes.com\n",
       "      True   \n",
       "10  \n",
       "\tInside Out Stuffed Peppers Recipe - Allrecip...     False   \n",
       "11     \n",
       "\tPerfect Pumpkin Pie Recipe - Allrecipes.com\n",
       "      True   \n",
       "12       \n",
       "\tCranberry Sauce I Recipe - Allrecipes.com\n",
       "     False   \n",
       "13       \n",
       "\tHalloween Cookies Recipe - Allrecipes.com\n",
       "      True   \n",
       "14              \n",
       "\tLiver Pate Recipe - Allrecipes.com\n",
       "      True   \n",
       "15    \n",
       "\tChicken Corn Chowder Recipe - Allrecipes.com\n",
       "      True   \n",
       "16  \n",
       "\tPineapple Angel Food Cake I Recipe - Allreci...     False   \n",
       "17  \n",
       "\tAsian Ground Beef and Pepper Saute Recipe - ...      True   \n",
       "18  \n",
       "\tNancy's Chicken in Puff Pastry Recipe - Allr...      True   \n",
       "19              \n",
       "\tFruit Dip Recipes - Allrecipes.com\n",
       "      True   \n",
       "20  \n",
       "\tSeven Minute Frosting I Recipe - Allrecipes....      True   \n",
       "21         \n",
       "\tWild Rice Pilaf Recipe - Allrecipes.com\n",
       "     False   \n",
       "22     \n",
       "\tSouthern Fried Corn Recipe - Allrecipes.com\n",
       "     False   \n",
       "\n",
       "            Meat types  \n",
       "0        [cheese, egg]  \n",
       "1                [egg]  \n",
       "2             [cheese]  \n",
       "3            [chicken]  \n",
       "4                [egg]  \n",
       "5                [egg]  \n",
       "6                   []  \n",
       "7             [cheese]  \n",
       "8                   []  \n",
       "9      [pork, chicken]  \n",
       "10                  []  \n",
       "11               [egg]  \n",
       "12                  []  \n",
       "13               [egg]  \n",
       "14           [chicken]  \n",
       "15  [chicken, chicken]  \n",
       "16                  []  \n",
       "17        [beef, beef]  \n",
       "18   [chicken, cheese]  \n",
       "19   [chicken, cheese]  \n",
       "20               [egg]  \n",
       "21                  []  \n",
       "22                  []  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loop for all recipes in folder\n",
    "# data has following row structure\n",
    "# RecipeName as Identifier - bool contains_meat - list of co2 ingredients - carbonFootprint - ingredients\n",
    "data=[]\n",
    "step=0\n",
    "\n",
    "verbose = 0 #verbose outputs\n",
    "\n",
    "for filename in os.listdir(SAMPLE_DATA_FOLDER):\n",
    "    with open(SAMPLE_DATA_FOLDER+filename) as f:\n",
    "        isTrue=False\n",
    "        count_exceptions=0\n",
    "        \n",
    "        # introduce try/catch such that it does no longer stop, when not recognizing letter\n",
    "        try:\n",
    "            page = f.read()\n",
    "            soup = BeautifulSoup(page, 'html.parser')\n",
    "            #print('filename: ', filename)\n",
    "            \n",
    "            #check webpage and extract ingredients if recognised as recipe\n",
    "            is_recipe, website = find_website(soup)\n",
    "            #print('This recipe is from: '+website)            \n",
    "            #print('Is_recipe: '+str(is_recipe))\n",
    "            \n",
    "            if is_recipe & (website=='allrecipes'):\n",
    "\n",
    "               \n",
    "                tags, ingredients = analyse_page(soup, website)\n",
    "                \n",
    "                if ingredients:\n",
    "                    #meat_ingredients_full, meat_ingredients_base, ingredient_quant, contains_meat = \\\n",
    "                    #                                                extract_meat(ingredients, meat_products)\n",
    "                    \n",
    "                    has_meat, meat_ingredients = contains_meat_ingredients(ingredients, meat_products)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    if verbose: \n",
    "                        print('Recipe Analysed: '+soup.title.string)\n",
    "                        \n",
    "                        print('contains meat:'+str(has_meat))\n",
    "                        print(meat_ingredients)\n",
    "                        \n",
    "                        print('{0} Ingredients: '.format(len(ingredients)))\n",
    "                        print(ingredients)\n",
    "\n",
    "                        print('{0} tags:'.format(len(tags)))\n",
    "                        print(tags)\n",
    "\n",
    "\n",
    "\n",
    "                    if verbose:\n",
    "                        print('does this recipe contain meat? ', contains_meat)\n",
    "                        \n",
    "                        if contains_meat:\n",
    "                            print('meat ingredients=', meat_ingredients_base)\n",
    "                            print('ingredient_quantity (kg)= ',ingredient_quant)\n",
    "                            \n",
    "                data.append([soup.title.string, has_meat, meat_ingredients])\n",
    "\n",
    "                \n",
    "            \n",
    "                #Extract meat ingredients and quantities in kg\n",
    "                \n",
    "                # extract meat ingredients, amounts, tags and store in dataframe\n",
    "                #extract amounts only for meat ingredients\n",
    "                \n",
    "\n",
    "               \n",
    "                \n",
    "                #data.append\n",
    "                #add row to dataset only if recipe contains meat\n",
    "                #data.append([soup.title.string, contains_meat, meatlist, carbon_fp(meatlist), ingredients])\n",
    "            #else:\n",
    "                #print('not a recipe')\n",
    "        except:\n",
    "            count_exceptions=count_exceptions+1\n",
    "            #print('Exception')\n",
    "    step=step+1\n",
    "    #print('-------------------------------------')\n",
    "    if step>=100:\n",
    "        break\n",
    "#print(data)\n",
    "column_labels=['Recipe Title', 'Has meat', 'Meat types']\n",
    "recipes_df = pd.DataFrame(data, columns = column_labels)\n",
    "recipes_df\n",
    "# save data as csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                #below: from Alex\n",
    "                #print('ingredient amount = ', ingredient_amounts)\n",
    "                meat_ingredients_full, meat_ingredients_base, ingredient_quant,contains_meat=extract_amount(ingredients, ingredient_amounts, meat_products)\n",
    "                print('does this recipe contain meat? ', contains_meat)\n",
    "                print('ingredients = ')\n",
    "                print(ingredients)\n",
    "                print('meat ingredients=', meat_ingredients_base)\n",
    "                print('ingredient_quantity (kg)= ',ingredient_quant)\n",
    "\n",
    "\n",
    "                #below: from Nadine\n",
    "                meatlist, contains_meat = analyse_meat(ingredient_wrappers,s)\n",
    "                ingredients = get_ingredients(ingredient_wrappers)\n",
    "                print('Ingredient list: ')\n",
    "                print(ingredients)\n",
    "                if meatlist:\n",
    "                    print('Has meat:')\n",
    "                    print(meatlist)\n",
    "                else:\n",
    "                    print('No meat detected')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada]",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
